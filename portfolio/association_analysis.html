<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head> 
<title>Association Analysis: Michael Rose</title>
<meta name="keywords" content="" />
<meta name="description" content="" />
<meta name="author" content="" />
<meta http-equiv="content-type" content="text/html;charset=utf-8" />
<meta http-equiv="Content-Style-Type" content="text/css" />
<link rel="stylesheet" href="css/blueprint/screen.css" type="text/css" media="screen, projection" />
<link rel="stylesheet" href="css/blueprint/print.css" type="text/css" media="print" />
<link rel="stylesheet" href="css/main.css" type="text/css" media="screen" /> 
<!--[if IE]>
  <link rel="stylesheet" href="css/blueprint/ie.css" type="text/css" media="screen, projection">
<![endif]-->
</head>
<body>
<div class="container">
  <h1>Data Mining Portfolio: Michael Rose</h1>
  <h2>Association Analysis</h2>
  <p class="introduction">Association Analysis is a method of discovering relationships hidden in large sets of data, such as market basket data. Unlike a traditional relationship, association rules are not bi-directional, just because when milk and cheese are bought so is toothpaste does not mean that toothpaste implies milk and cheese ({milk, cheese} => {toothpaste}). Building a model using this concept comes down to the proper generation of frequent itemsets and rule generation. A priori allows us to generate frequent itemsets and then we can apply them.</p>
  <h3>Model Building</h3>
  <p>
    Two major tasks of building association rules are frequent itemset generation and rule generation. Frequent itemset generation generates itemsets that reach some support confidence (see support below). As with any combinatorial/permutation problem, it is prohibitively expensive to generate all possibilities. The goal is to generate rules of high confidence using the frequent itemsets. A concept which helps implement this is the "a priori" principle. A priori says that if an itemset is frequent, all of its subsets must be frequent, conversely if an itemset is infrequent then its supersets must also be infrequent. This is known as support-based pruning. After choosing a support threshold, the support is calculated for all 1 itemsets, those which do not meet the criteria are removed from consideration. Using the F_k x F_(k-1) algorithm, the 1-itemsets are combined to create 2-itemsets and so on and soforth until all frequent itemsets are created.
  </p>
  <p>
    Rule generation begins given the frequent itemsets. Each of the k-itemsets can produce up to 2^k-2 rules. The general algorithm extracts all high-confidence rules with one item in the consequent to generate more candidate rules. Association rules are then generated by partitioning the itemsets into two subsets that satisfy the confidence threshold. They have already met the support threshhold, and these rules can be merged to create new rules through an a priori approach as discussed above.
  </p>
  <p>
    The support supp(X) of an itemset X is defined as the proportion of transactions in the data set which contain the itemset.
    <img alt="Confident" src="images/association_analysis/confidence.png" />
    <br />
    <br />
    <br />
    <br />
  </p>
  <h3>Use Cases</h3>
  <p>
    Association analysis is used by large corporations with transaction data. By generating rules given market basket data, they can find items which are likely to imply the purchase of other items and cluster these items in stores. Unfortunately, association analysis can be costly in terms of computational cost, the lower support threshhold the more time is required to generate rules. In our application the Classic Mushroom Dataset association analysis created the best rules and classifiers.ÃŸ
  </p>
</div>
</body>
</html>