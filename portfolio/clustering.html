<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head> 
<title>NAME OF DATA MINING STRATEGY</title>
<meta name="keywords" content="" />
<meta name="description" content="" />
<meta name="author" content="" />
<meta http-equiv="content-type" content="text/html;charset=utf-8" />
<meta http-equiv="Content-Style-Type" content="text/css" />
<link rel="stylesheet" href="css/blueprint/screen.css" type="text/css" media="screen, projection" />
<link rel="stylesheet" href="css/blueprint/print.css" type="text/css" media="print" />
<link rel="stylesheet" href="css/main.css" type="text/css" media="screen" /> 
<!--[if IE]>
  <link rel="stylesheet" href="css/blueprint/ie.css" type="text/css" media="screen, projection">
<![endif]-->
</head>
<body>
<div class="container">
  <h1>Data Mining Portfolio: Michael Rose</h1>
  <h2>Clustering Algorithms</h2>
  <p class="introduction">Clustering is the process of taking a set of data and processing it such that groups in the data become quantifiable. These algorithms and others like them are designed to take the process of grouping (a task humans excel at) and do so on a large scale and find groups which may not be apparent to the average human being. Many times, the groups clustering algorithms find are not apparent when processing begins and only after the algorithms complete can class labels be assigned. Classification algorithms undergo similar processes, but have predefined class labels (and numbers of groups) to sort data objects into. Another difference between clustering and classification can be found in the timing of processing, generally classifiers are built (trained) with large initial outsets of processing time (and relatively cheap classification thereafter) versus clustering which is real-time processing of data.</p>
  <h3>K-Means Clustering</h3>
  <p>
    K-Means clustering is a relatively simple algorithm which takes takes a parameter <strong>k</strong>, the number of clusters to attempt to create, and randomly picks centroids for these k clusters. Each point in the dataset then finds the centroid it's closest to and these points are grouped into k groups of points. These original centroids are then adjusted to be the centroids of the group of points. This process iteratively continues until the centroids stop moving (by some epsilon amount) or the max number of iterations is reached. This algorithm is simple, fast, and generally effective. Downsides of this algorithm are its extreme sensitivity to noise and inability to easily distinguish two close clusters. Additionally, K-Means does not handle oddly shaped clusters, such as DBScan does.
  </p>
  <script src="http://gist-it.appspot.com/github/Xorlev/csci568/raw/master/project05/kmeans.rb"></script>
  <h3>Agglomerative Hierarchical</h3>
  <p>
    ...
  </p>
  <h3>DBScan</h3>
  <p>
    ...
  </p>
</div>
</body>
</html>